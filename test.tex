%------------------------------------------------------------------------
\chapter{Introduction}
\label{Introduction.ch}
%------------------------------------------------------------------------
A stereotypical image of a robot is a humanoid in a servant costume which can do all the chores at home and perhaps even more. 
This is not too far from scientific projects which are being run in research labs. 
Assuming such goal, human behavior becomes a natural inspiration for the algorithms governing the behavior of a robot in the 
assigned tasks and situations.
Imagining a simple but common task of find-and-fetch, first solution that could be thought of, is to learn how exactly a human 
would perform the task. 
Then, how the procedure can be translated to an algorithm executable on a robotic system.
% But trying to make a system to imitate human behavior to perform a task, is not always the best solution. 
% As our system usually has different qualifications and also limits compared to a human body. 
% Moreover , it is not always easy to understand how a human really performs a task, and how the brain make decisions. 
% But it can always give a good idea to start with.
Often such translation can not be direct due to the differences in embodiments and lack of complete understanding of underlying 
processes. 

In case of the find-and-fetch task, a human is likely to imagine what does the target object look like, where and it what situation 
it is often found.
If the object is known, a natural behavior is to visit the most probable location for the object first.
only in the worst case scenario and without the knowledge of the object, one would perform a thorough search of the whole scene.
In other words, the strategy depends on the amount of information about the target object. 
%Returning to our Find-and-fetch task; When such a task is given to a human, The first step for him 
%would be imagining what does the asked object look like and where and in what situation it is supposed to be located.
%If the object is known to him, he goes to the fist location that is most probable place for finding it and then looks for visually 
%similar object to the picture he has in mind of the asked object in that location.
%If he does not have any information about the object, first he needs to get some from a description or a picture of it.
%Then he gets some information about possible locations as well. It would be the worst case that he starts just by looking
%everywhere for something similar to the seen picture or heard description. 
%Depending on amount of information he has ,the amount of time he will need to find the object is different.

A similar behavior could be implemented on a mobile robot. 
A valuable prior knowledge for an object detection/recognition problem could be semantic knowledge about places and possible context for the object, 
which not only can reduce the search time but also can increase the chance of success and correctness of the results.

Torralba et al. in \cite{eyeMovement} point to the fact that there are many experiments showing that the human visual system uses 
contextual information to facilitate search for objects. 
Moreover, he proposes the use of context for object detection in 2D images.
%Although, it is also mentioned that how this information is applied in the process is not completely known to scientists yet.

%To clarify what is considered as object context in this work, it should be mentioned that surfaces that surround an object as 
%a single body is a context for the object. 
In this work, we focus on 3D information and therefore, consider surfaces surrounding the object as its context.
This includes surfaces the object is located on or next to and also other objects which are usually
beside the object of interest. 
For instance, if the object of interest is a $kitchen$ $water$ $tap$, it's context ca be the 
$kitchen$ $sink$ and the wall behind it. (Figure ~\ref{contextExample.figure})

\begin{figure}[t]
  \centerpsw{contextExample}{0.65\columnwidth}
  \caption[Illustration of a sample Context.]
  {A water tap as the object of interest and what we call its context. The context is surfaces within the green 
  bounding box.}
  \label{contextExample.figure}
\end{figure}

%----------------------------------------------------------------------------
\section {Contributions}
\label{Contributions.sec}
%----------------------------------------------------------------------------

In this work, we propose a method to build 3D models of object context, which not only can be used as a prior to an object detector,
but also as a useful knowledge in building 3D representation for places. 
Benefiting from this model, the area needed to be searched in an object detection task can be reduced to parts of the scene with high 
probability of being the context for the object of interest. 
It can also have a positive effect on number of true positive in prediction results. 
Combining the information encoded in this model with other features and structural information of different place categories can 
result in a representation for places.
 
 To build Object context models we applied supervised learning methods on data extracted from manually annotated objects in 
 point-clouds. Point-closed that we used as input are ful 3D representaions of a place such as an office, a kitchen, etc. 
 The learning  is done on features which are representing local geometry and spacial location of object context.
 
 Most important points about this work ca be briefly mentioned as follows:
 
 \begin{itemize}
  \item Emphasizing on the role of context in object detection and it's related applications.
  \item The features and methodology suggested to model the Object Context.
  \item The input data used in this work are full point-clouds of places rather than single frames with depth information or 
  2D images.
  \item Suggesting the application of Context model in place classification.
  
 \end{itemize}

 
Applications in place classification would be discussed later in chapter \ref{UsingObjectContextforPlaceClassification.ch}.

\section {Related Work}
\label{RelatedWork.sec}
     In this section, some related works focusing on using contextual information for object detection/recognition 
     or place classification are briefly reviewed. 
     Moreover, other works which contribute 3D features and descriptors for similar purposes are mentioned.
     
\subsection*{Object Context}
     In \cite{TrollbaContexBased} Torralba et al. present a low dimensional global image representation
     capturing useful information for recognition of places and show how contextual information can provide priors for object
     recognition. 
     As mentioned before, this work considers 2D images only. 
     
     In \cite{TorralbaContextualPriming} Torralba uses the relationship between object and it's context properties from 
     2D images to build model that helps the focus of an object detector's attention and also for scale selection. 
      
     In \cite{PerkoLeonardisContextDriven} Perko and Leonardis extract and learn contextual information for objects from examples.
     Then they use this learned context to calculate a focus of attention, that represents a prior for object detection. Their work is 
     also used 2D features extracted from images. 
 
      Aydemir et al. in \cite{aydemir2012_3Dcontext} learn 3D context of objects to predict object locations in 
      real world scenes. 
      They used separate RGB and depth frames and used histograms of surface normals as a 3D geometrical feature
      to model object context.
      
    In \cite{5651280} Rusu et al. proposed Viewpoint Feature Histogram that encodes 3D geometry and pose. They suggested that this descriptor
    can be used for object recognition and pose estimation with high reliability.
    In this work we employ a descriptor, which contains their descriptor, for modeling context of objects.
     
\subsection*{Place classification}

    In \cite{Vasudevan2008522}, Vasudevan and Siegwart proposed a representation for space based on objects. 
    The authors discuss several algorithms, some of which only uses object category presence and some are more sophisticated using both 
    objects and their relationships and also spacial structure of places.
     
\section {Outline}
\label{Outline.sec}
The rest of this thesis is structured as follows:
In chapter \ref{ModelingObjectContext.ch}, the problem definition and more about motivation, applications and challenges would be 
presented.
chapter\ref{3DModelofObjectContext.ch}, dwscribes our method and details about implementation, experiments and evaluation. 
In chapter\ref{UsingObjectContextforPlaceClassification.ch}, applications of our model and descriptor in place classification is 
discussed and an analytical study is done for the results that could be expected for this application.
Finally, we have a review while next steps that could be considered for this work and possible improvements 
and also future works are mentioned in \ref{Conclusion.ch}.
