%------------------------------------------------------------------------
\chapter{Introduction}
\label{Introduction.ch}
%------------------------------------------------------------------------
A stereotypical image of a robot is a humanoid in a servant costume which can do all the chores at home and perhaps even more. 
%This is not too far from scientific projects which are being run in research labs. 
Assuming such goal, human behavior becomes a natural inspiration for the algorithms governing the behavior of a robot in the 
assigned tasks and situations.
Imagining a simple but common task of find-and-fetch, in which a mobile robot is asked to find an object and bring it 
to the user. 
The first solution that could be thought of, is to learn how exactly a human would perform the task. 
Then, how the procedure can be translated to an algorithm executable on a robotic system.
% But trying to make a system to imitate human behavior to perform a task, is not always the best solution. 
% As our system usually has different qualifications and also limits compared to a human body. 
% Moreover, it is not always easy to understand how a human really performs a task, and how the brain make decisions. 
% But it can always give a good idea to start with.
Often such translation can not be direct due to the differences in embodiments and lack of complete understanding of 
underlying processes. 

In case of the find-and-fetch task, if it is assigned to a human agent, he is likely to imagine what does the target 
object look like, where and in what situation it is often found.
If the object is known, a natural behavior is to visit the most probable location for the object first.
Only in the worst case scenario and without the knowledge of the object, one would perform a through search of the 
whole scene.
In other words, the strategy depends on the amount of information about the target object. 
%Returning to our Find-and-fetch task; When such a task is given to a human, The first step for him 
%would be imagining what does the asked object look like and where and in what situation it is supposed to be located.
%If the object is known to him, he goes to the fist location that is most probable place for finding it and then looks for visually 
%similar object to the picture he has in mind of the asked object in that location.
%If he does not have any information about the object, first he needs to get some from a description or a picture of it.
%Then he gets some information about possible locations as well. It would be the worst case that he starts just by looking
%everywhere for something similar to the seen picture or heard description. 
%Depending on amount of information he has,the amount of time he will need to find the object is different.

A similar behavior could be implemented on a mobile robot. 
A valuable prior knowledge for an object detection/recognition problem could be semantic knowledge about places and possible context for the object, 
which not only can reduce the search time but also can increase the chance of success and correctness of the results.

Torralba et al. in \cite{eyeMovement} point to the fact that there are many experiments showing that the human visual system uses 
contextual information to facilitate search for objects. 
Moreover, he proposes the use of context for object detection in 2D images.
%Although, it is also mentioned that how this information is applied in the process is not completely known to scientists yet.

%To clarify what is considered as object context in this work, it should be mentioned that surfaces that surround an object as 
%a single body is a context for the object. 
In this work, we focus on 3D information and therefore, consider surfaces surrounding the object as its context.
This includes surfaces the object is located on or next to and also other objects which are usually
beside the object of interest. 
For instance, if the object of interest is a $kitchen$ $water$ $tap$, it's context ca be the 
$kitchen$ $sink$ and the wall behind it. (Figure ~\ref{contextExample.figure})

\begin{figure}[t]
  \centerpsw{contextExample}{0.65\columnwidth}
  \caption[Illustration of a sample Context.]
  {A water tap as the object of interest and what we call its context. The context is surfaces within the green 
  bounding box.}
  \label{contextExample.figure}
\end{figure}

%----------------------------------------------------------------------------
\section {Contributions}
\label{Contributions.sec}
%----------------------------------------------------------------------------

In this work, we propose a method to build models of 3D object context, which not only can be used as a prior to an 
object detector, but also as a useful knowledge in building 3D representation for places. 
Benefiting from this model, the area needed to be searched in an object detection task can be reduced to parts of the scene with high 
probability of being the context for the object of interest. 
It can also have a positive effect on number of true positives in prediction results. 
Combining the information encoded in this model with other features and structural information of different place categories can 
result in a representation for places.
 
 To build Object context models we applied supervised learning methods on data extracted from manually annotated objects in 
 point-clouds. Point-closed that we used as input are full 3D representations of a place such as an office, a kitchen, etc. 
 The learning  is done on features which are representing local geometry and spacial location of object context.
 
 Most important points about this work ca be briefly mentioned as follows:
 
 \begin{itemize}
  \item Emphasizing on the role of context in object detection and its related applications.
  \item The feature descriptor and methodology suggested to extract features and model the Object Context.
  \item The input data used in this work are full point-clouds of places rather than single frames with depth information or 
  2D images.
  \item Suggesting the application of Context model in place classification and proposing a method to do it.
  
 \end{itemize}

 
Applications in place classification would be discussed later in chapter \ref{UsingObjectContextforPlaceClassification.ch}.

\section {Related Work}
\label{RelatedWork.sec}
     In this Section, some related works focusing on using contextual information for object detection/recognition 
     or place classification are briefly reviewed. 
     Moreover, other works which contribute 3D features and descriptors for similar purposes are mentioned.
     
%\subsection*{Object Context}
The usefulness of contextual information for object detection and recognition is discussed and
considered in \cite{TrollbaContexBased}, \cite{TorralbaContextualPriming}, \cite{PerkoLeonardisContextDriven}
and \cite{aydemir2012_3Dcontext}.
Torralba et al. in \cite{TrollbaContexBased}, present a low dimensional global image 
     representation capturing useful information for recognition of places and show how contextual 
     information can provide priors for object recognition.
     So in this work a place category is considered as a context for objects.
     They suggested that knowing the category of a place helps finding objects that are relevant to
     that place category.
     We have a more fine grained definition for context of the object which is limited to a 
     vicinity around the object.
     In this work we are suggesting an opposite direction which is using local object context information
     can help us in recognizing the category of a place.
     
     Torralba in In \cite{TorralbaContextualPriming}, Perko and Leonardis in In \cite{PerkoLeonardisContextDriven}
     and Aydemir et al. in  \cite{aydemir2012_3Dcontext} train models for object context to focus
     the attention of object detectors to reduced search regions which match the learned models.
     In these works the definition of object context become closer to what we consider.
     
2D features extracted from images are the information used in \cite{TrollbaContexBased}, 
\cite{TorralbaContextualPriming} and \cite{PerkoLeonardisContextDriven} while in \cite{aydemir2012_3Dcontext}
3D information extracted from RGB-D frames builds models of 3D object context.
The later also analyzed the improvement in the performance of available object detectors using context information.
      
      we use 3D information and features from full pointclouds of a place not just single frames 
      which helps capturing spacial relations in the whole captured space.
      It is useful especially in place representation.
      
    In \cite{5651280} Rusu et al. proposed Viewpoint Feature Histogram that encodes 3D geometry and pose. 
    They suggested that this descriptor can be used for object recognition and pose estimation with high reliability.
    In this work we employ a feature descriptor, which contains their descriptor, for modeling context of objects.
    By the feature extraction method we are proposing in this work, their descriptor is being used in a specific and 
    novel way.
    In contrast of its suggested usage to be extracted as a global descriptor for a pointcloud, based on a fixed view point,
    we are extracting it for several small subsets of a pointcloud and from several distinct viewpoints.
    It is discuss in detail in Section \ref{Implementation.sec}.
     
\subsection*{Place classification}

    In \cite{Vasudevan2008522}, Vasudevan and Siegwart proposed a representation for space based on objects. 
    The authors discuss several algorithms, some of which only uses object category presence and some are more 
    sophisticated using both objects and their relationships and also spacial structure of places.
    
    More researches are discussed later in Chapter \ref{UsingObjectContextforPlaceClassification.ch} which is 
    specifically devoted to this particular application.
     
\section {Outline}
\label{Outline.sec}
The rest of this thesis is structured as follows:
In Chapter \ref{ModelingObjectContext.ch}, the problem definition and more about motivation, applications and 
challenges are presented.
Chapter\ref{3DModelofObjectContext.ch}, describes our method and details about implementation, experiments and evaluation. 
In Chapter\ref{UsingObjectContextforPlaceClassification.ch}, applications of our model and descriptor in place classification is 
discussed and an analytical study is done for the results that could be expected for this application.
Finally, we have a review while next steps that could be considered for this work, possible improvements 
and also future works are mentioned in Chapter \ref{Conclusion.ch}.

